#!/bin/python

# ======================================================= IMPORTS & MODULE SETUP


import os
import sys
import signal
import subprocess as sh
from datetime import datetime
from types import FrameType
from functools import partial

from CatalisUtils.logging import Logger

from time import sleep, strftime, gmtime
import apsw, apsw.bestpractice


# initialize apsw
apsw.bestpractice.apply((
	apsw.bestpractice.connection_busy_timeout,
	apsw.bestpractice.connection_enable_foreign_keys,
	apsw.bestpractice.connection_dqs
))


# ================================================================= CONFIG SETUP


# create config object
class CFG:
	FSTYPE 			= os.environ.get("CATALIS_FSTYPE", 							"vfat")
	LABEL_PREFIX 	= os.environ.get("CATALIS_LABEL_PREFIX", 					"DATA-HMI")
	MOUNTPOINT 		= os.environ.get("CATALIS_MOUNTPOINT", 						"/srv/CatalisDATA/")
	DB_SUBDIR 		= os.environ.get("CATALIS_DB_SUBDIR", 						"current/")
	DB_PATTERN 		= os.environ.get("CATALIS_DB_PATTERN", 						"polldata-hmi$HMID")
	HMI_HOST 		= os.environ.get("CATALIS_HMI_HOST", 						"192.168.1.2")
	BUSY_RETRY_INT 	= os.environ.get("CATALIS_DB_BUSY_RETRY_INTERVAL", 			"10")
	SYNCING_FREQ 	= os.environ.get("CATALIS_SYNCING_FREQUENCY", 				"30")
	CONN_RETRY_INT 	= os.environ.get("CATALIS_SYNC_DB_CONNECT_RETRY_INTERVAL", 	"60")


# ================================================================== MAIN DAEMON


# daemon
def daemon() -> None:
	# initialize logger 
	logger = Logger(logfile=f"/var/log/catalis/csync-{strftime('%d%m%Y-%H%M%S', gmtime())}.log")

	# register custom standard termination exit handler
	signal.signal(signal.SIGTERM, partial(exit_clean, logger))

	# write to journalctl log
	sh.run(f"echo 'Daemon started. Logging to {logger}.'", shell=True)

	# get filesystem label
	fs_label = sh.getoutput(f"lsblk -o label /dev/{sys.argv[1]} | tail -1")

	# initial information
	logger.print(f"Welcome to the Catalis Cloud HMI Poller Daemon")
	logger.print(f"Session date: {strftime('%F', gmtime())} (GMT)")
	logger.print(f"Filesystem label: {fs_label}")
	logger.print(f"Mount point: {CFG.MOUNTPOINT}")
	logger.print(f"HMI TCP/IP host address: {CFG.HMI_HOST}\n")


	# initialize database connection
	logger.log("(init) <1/1> Initializing database connection Read-Write mode... ", endline=False)

	while True:
		try:
			hmid = fs_label.strip(CFG.LABEL_PREFIX)
			dbpath = os.path.join(CFG.MOUNTPOINT, CFG.DB_SUBDIR, (f"{CFG.DB_PATTERN}.sqlite3").replace("$HMID", hmid))

			db = apsw.Connection(dbpath, flags=apsw.SQLITE_OPEN_READWRITE)
			db.set_busy_handler(partial(db_busy_handler, logger))
			
			logger.log(f"connected to {dbpath}.")
			break
		
		except apsw.CantOpenError:
			logger.log("error.")
			logger.log(f"Error initializing database connection. Trying again in {CFG.CONN_RETRY_INT}s...", level=Logger.ERROR, endline=False)

			sleep(int(CFG.CONN_RETRY_INT))


	# main upload loop
	synccount = 1

	while True:
		# print visual separator
		logger.print("---------|")

		# read latest polls
		logger.log(f"(sync~{synccount:03}) <1/2> Fetching latest packets from database... ", endline=False)
		
		while True:
			lastsync = list(db.execute("SELECT value FROM meta WHERE type=?", ("lastsync", )))[0][0]
			data = list(db.execute("SELECT * FROM packets WHERE timestamp > ? ORDER BY timestamp ASC;", (lastsync, )))

			# if any new polls...
			if data:
				logger.log(f"fetched {len(data)} entries, from {datetime.utcfromtimestamp(int(lastsync)).strftime('%T')} upwards.")
				
				# do stuff
				# for row in data:
				# 	logger.print(row)

				# set sync state to last entry's timestamp
				try:
					logger.log(f"(sync~{synccount:03}) <2/2> Updating sync state... ", endline=False)
					db.execute("UPDATE meta SET value=? WHERE type=?", (data[-1][1], "lastsync" ))
					logger.log(f"latest sync timestamp: {datetime.utcfromtimestamp(int(lastsync)).strftime('%T')}.")
				
				# on failure, throw fatal error...
				except apsw.ReadOnlyError as e1:
					logger.log("error.")
					logger.log(f"Failed while writing to database - ", level=Logger.FATAL, endline=False)

					try: # check if can open db, if yes assume permissions error
						test = apsw.Connection(dbpath, flags=apsw.SQLITE_OPEN_READWRITE)
						
						logger.log(("check mounted filesytem permissions (Sugg. "
				  					"fixes: Re-insert the storage volume to restart "
									"all services)."))
						logger.log(e1, level=Logger.TRACE)

					except apsw.CantOpenError as e2: 
						logger.log(("ensure local DB has not been deleted (Sugg. "
				  					"fixes: Re-insert the storage volume to restart "
									"all services)."))					
						logger.log(e2, level=Logger.TRACE)
					
					exit_fatal(logger)

				synccount += 1

			else:
				logger.log("no new entries.")

			sleep(int(CFG.SYNCING_FREQ))
			break


# ============================================================== CUSTOM HANDLERS


# sqlite db busy handler
def db_busy_handler(logger:Logger, priorcalls:int):
	logger.cap("error.")
	logger.log(f"Database is busy - trying again in {CFG.BUSY_RETRY_INT}s... ", level=Logger.ERROR, endline=False)
	sleep(int(CFG.BUSY_RETRY_INT))
	return True


# custom clean exit handler
def exit_clean(logger:Logger, signum:int, frame:FrameType) -> None:
	logger.print(f"\nTerminated cleanly at {strftime('%T', gmtime())}.")
	sh.run(f"echo 'Daemon exiting cleanly.'", shell=True) # write to journalctl log
	sys.exit(0)


# custom error exit handler
def exit_fatal(logger:Logger) -> None:
	logger.print(f"\nTerminated due to fatal error at {strftime('%T', gmtime())}.")
	sh.run(f"echo 'Daemon exiting with fatal error. Check log: {logger}'", shell=True) # write to journalctl log
	sys.exit(1)


# ================================================================== DRIVER CODE


# driver
if __name__ == "__main__":
	daemon()